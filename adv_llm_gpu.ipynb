{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v1lgJ9og8r25",
    "outputId": "47145e07-07e5-41ca-dae7-56adba248bd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version\n",
      "3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:40:32) [GCC 12.3.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Print the Python version\n",
    "print(\"Python version\")\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VD8axkr_9541",
    "outputId": "c6f40a55-a6ee-43e9-ea06-ac5913c7eedf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec  1 11:57:15 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            On   | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   42C    P8    10W /  70W |      2MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla T4            On   | 00000000:00:05.0 Off |                    0 |\n",
      "| N/A   42C    P8     9W /  70W |      2MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla T4            On   | 00000000:00:06.0 Off |                    0 |\n",
      "| N/A   43C    P8    10W /  70W |      2MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla T4            On   | 00000000:00:07.0 Off |                    0 |\n",
      "| N/A   43C    P8    10W /  70W |      2MiB / 15360MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -q huggingface-hub>=0.17.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8Cp6XZDcVlQ",
    "outputId": "e21efdf2-45cf-4978-a07e-245bbb884767"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import huggingface_hub\n",
    "huggingface_hub.login(token='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')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uy-4v6Qg-pGP",
    "outputId": "fbaf343d-ce14-4c56-c4b8-e47944d3619b"
   },
   "source": [
    ">!huggingface-cli download TheBloke/med42-70B-AWQ --local-dir ./med42-70B-AWQ --local-dir-use-symlinks False\n",
    "...\n",
    "Fetching 18 files: 100%|████████████████████████| 18/18 [03:02<00:00, 10.11s/it]\n",
    "/home/jupyter/med42-70B-AWQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B-mIN9uF-ZhK",
    "outputId": "e79918f7-c95e-4be1-8987-f3bd000e2068"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 4\n",
      "GPU 0: Tesla T4\n",
      "GPU 1: Tesla T4\n",
      "GPU 2: Tesla T4\n",
      "GPU 3: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "# To check gpu\n",
    "import torch\n",
    "print(\"Number of GPUs available:\", torch.cuda.device_count())\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-AWcavjsm768",
    "outputId": "2576763d-1618-4250-e621-b246f69b0287"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "n_threads = os.cpu_count()\n",
    "n_threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 12-01 11:59:55 config.py:140] awq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 11:59:59,143\tINFO worker.py:1633 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-01 12:00:00 llm_engine.py:72] Initializing an LLM engine with config: model='./med42-70B-AWQ', tokenizer='./med42-70B-AWQ', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=4, quantization=awq, seed=0)\n",
      "INFO 12-01 12:08:46 llm_engine.py:207] # GPU blocks: 3233, # CPU blocks: 3276\n",
      "CPU times: user 2.47 s, sys: 1.15 s, total: 3.62 s\n",
      "Wall time: 8min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from vllm import LLM, SamplingParams\n",
    "\n",
    "llm = LLM(model=\"./med42-70B-AWQ\", quantization=\"awq\", dtype=\"auto\", tensor_parallel_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZlMpaQ3G-tBL",
    "outputId": "53f2001c-beb6-4297-94ea-669d74f579bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 4/4 [00:23<00:00,  5.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: '<|system|>: You are a helpful medical assistant created by M42 Health in the UAE.\\n<|prompter|>:Tell me about AI\\n<|assistant|>:\\n', Generated text: ' Artificial intelligence (AI) is a branch of computer science that aims to infuse intelligence into machines. This includes the development of algorithms and software that can perform tasks that would typically require human intelligence, such as visual perception, speech recognition, decision-making, and language translation.\\n\\nThe concept of AI has been around for centuries, but it has gained significant traction in the past few decades as technology has advanced. Today, AI is being used in various industries, including healthcare, education, finance, transportation, and entertainment, among others.\\n\\nIn healthcare, for instance, AI is being used to develop personalized treatment plans, diagnose diseases, and assist in surgical procedures. In education, AI is being used to develop adaptive learning systems that can tailor the learning experience to individual needs. In finance, AI is being used for fraud detection and risk assessment. In transportation, AI is being used for self-driving cars and traffic management systems. In entertainment, AI is being used for content recommendation and game development.\\n\\nOverall, AI has the potential to revolutionize various aspects of our lives and improve efficiency,'\n",
      "Prompt: '<|system|>: You are a helpful medical assistant created by M42 Health in the UAE.\\n<|prompter|>:Write a story about llamas\\n<|assistant|>:\\n', Generated text: 'Once upon a time, in a small village nestled in the Andes mountains, there lived a group of friendly and hardworking llamas. These llamas were known for their gentle nature, their fluffy fur, and their ability to carry heavy loads up and down the mountain paths.\\n\\nOne day, the village chief decided to organize a great celebration to honor the llamas for their service to the community. The villagers prepared a feast, with plenty of fresh grass and juicy fruits for the llamas to enjoy. They also decorated the village with colorful streamers and balloons, creating a festive atmosphere.\\n\\nAs the sun began to set, the villagers gathered around a large bonfire, sharing stories and laughter. The llamas, feeling the warmth of the fire and the love of the villagers, began to dance and play together, creating a joyful spectacle for everyone to see.\\n\\nSuddenly, a loud rumble was heard in the distance, and the ground began to shake. The villagers and the llamas looked up in surprise as a giant llama, twice the size of any llama they had ever seen, descended from the sky.'\n",
      "Prompt: '<|system|>: You are a helpful medical assistant created by M42 Health in the UAE.\\n<|prompter|>:What is 291 - 150?\\n<|assistant|>:\\n', Generated text: ' The result of 291 - 150 is 141.'\n",
      "Prompt: '<|system|>: You are a helpful medical assistant created by M42 Health in the UAE.\\n<|prompter|>:How much wood would a woodchuck chuck if a woodchuck could chuck wood?\\n<|assistant|>:\\n', Generated text: ' A woodchuck, also known as a groundhog, can indeed chuck wood. However, the amount of wood a woodchuck could chuck would depend on several factors, such as the size and strength of the woodchuck, as well as the size and weight of the wood it is attempting to chuck. Generally, a woodchuck can chuck a piece of wood that is smaller than itself, but the exact amount would vary.'\n",
      "CPU times: user 1.06 s, sys: 98.3 ms, total: 1.15 s\n",
      "Wall time: 23.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prompts = [\n",
    "    \"Tell me about AI\",\n",
    "    \"Write a story about llamas\",\n",
    "    \"What is 291 - 150?\",\n",
    "    \"How much wood would a woodchuck chuck if a woodchuck could chuck wood?\",\n",
    "]\n",
    "prompt_template='''<|system|>: You are a helpful medical assistant created by M42 Health in the UAE.\n",
    "<|prompter|>:{prompt}\n",
    "<|assistant|>:\n",
    "'''\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0.1,\n",
    "    top_p=0.95,\n",
    "    top_k=50,\n",
    "    max_tokens=256\n",
    ")\n",
    "\n",
    "prompts = [prompt_template.format(prompt=prompt) for prompt in prompts]\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "\n",
    "# Print the outputs.\n",
    "for output in outputs:\n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "    print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "jtrMFTuT_3Pg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# More about data: https://www.kaggle.com/datasets/tboyle10/medicaltranscriptions\n",
    "\n",
    "# Specify the file path (this path should point to where your file is stored)\n",
    "BASE_PATH = './'\n",
    "file_path = BASE_PATH + 'mtsamples.csv'\n",
    "\n",
    "# Read data as pandas DataFrame\n",
    "data = pd.read_csv(file_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "TU8KVTIzcpXa",
    "outputId": "556858d0-549b-4643-c3f9-bb2bbc6f3bda"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>sample_name</th>\n",
       "      <th>transcription</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A 23-year-old white female presents with comp...</td>\n",
       "      <td>Allergy / Immunology</td>\n",
       "      <td>Allergic Rhinitis</td>\n",
       "      <td>SUBJECTIVE:,  This 23-year-old white female pr...</td>\n",
       "      <td>allergy / immunology, allergic rhinitis, aller...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Consult for laparoscopic gastric bypass.</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Laparoscopic Gastric Bypass Consult - 2</td>\n",
       "      <td>PAST MEDICAL HISTORY:, He has difficulty climb...</td>\n",
       "      <td>bariatrics, laparoscopic gastric bypass, weigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Consult for laparoscopic gastric bypass.</td>\n",
       "      <td>Bariatrics</td>\n",
       "      <td>Laparoscopic Gastric Bypass Consult - 1</td>\n",
       "      <td>HISTORY OF PRESENT ILLNESS: , I have seen ABC ...</td>\n",
       "      <td>bariatrics, laparoscopic gastric bypass, heart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-D M-Mode. Doppler.</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 1</td>\n",
       "      <td>2-D M-MODE: , ,1.  Left atrial enlargement wit...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d m-mode, dopple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2-D Echocardiogram</td>\n",
       "      <td>Cardiovascular / Pulmonary</td>\n",
       "      <td>2-D Echocardiogram - 2</td>\n",
       "      <td>1.  The left ventricular cavity size and wall ...</td>\n",
       "      <td>cardiovascular / pulmonary, 2-d, doppler, echo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  \\\n",
       "0   A 23-year-old white female presents with comp...   \n",
       "1           Consult for laparoscopic gastric bypass.   \n",
       "2           Consult for laparoscopic gastric bypass.   \n",
       "3                             2-D M-Mode. Doppler.     \n",
       "4                                 2-D Echocardiogram   \n",
       "\n",
       "             medical_specialty                                sample_name  \\\n",
       "0         Allergy / Immunology                         Allergic Rhinitis    \n",
       "1                   Bariatrics   Laparoscopic Gastric Bypass Consult - 2    \n",
       "2                   Bariatrics   Laparoscopic Gastric Bypass Consult - 1    \n",
       "3   Cardiovascular / Pulmonary                    2-D Echocardiogram - 1    \n",
       "4   Cardiovascular / Pulmonary                    2-D Echocardiogram - 2    \n",
       "\n",
       "                                       transcription  \\\n",
       "0  SUBJECTIVE:,  This 23-year-old white female pr...   \n",
       "1  PAST MEDICAL HISTORY:, He has difficulty climb...   \n",
       "2  HISTORY OF PRESENT ILLNESS: , I have seen ABC ...   \n",
       "3  2-D M-MODE: , ,1.  Left atrial enlargement wit...   \n",
       "4  1.  The left ventricular cavity size and wall ...   \n",
       "\n",
       "                                            keywords  \n",
       "0  allergy / immunology, allergic rhinitis, aller...  \n",
       "1  bariatrics, laparoscopic gastric bypass, weigh...  \n",
       "2  bariatrics, laparoscopic gastric bypass, heart...  \n",
       "3  cardiovascular / pulmonary, 2-d m-mode, dopple...  \n",
       "4  cardiovascular / pulmonary, 2-d, doppler, echo...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BrowZCeoN-Cp"
   },
   "source": [
    "# Case: Medical specialty classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GCetCvuOdxpi",
    "outputId": "230a155e-72b7-4991-9264-9904acac07c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medical_specialty\n",
       " Surgery                       0.220644\n",
       " Consult - History and Phy.    0.103221\n",
       " Cardiovascular / Pulmonary    0.074415\n",
       " Orthopedic                    0.071014\n",
       " Radiology                     0.054611\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['medical_specialty'].value_counts(normalize=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "aH3C5IflcpaE"
   },
   "outputs": [],
   "source": [
    "specialties = data['medical_specialty'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-rkOK6MUfPBT",
    "outputId": "36638954-9d83-45d9-c69b-9dddf963bf41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -  Allergy / Immunology\n",
      " -  Bariatrics\n",
      " -  Cardiovascular / Pulmonary\n",
      " -  Neurology\n",
      " -  Dentistry\n",
      " -  Urology\n",
      " -  General Medicine\n",
      " -  Surgery\n",
      " -  Speech - Language\n",
      " -  SOAP / Chart / Progress Notes \n",
      "...\n"
     ]
    }
   ],
   "source": [
    "specialties_text = '\\n - '+'\\n - '.join(specialties)\n",
    "print(specialties_text[:200],'\\n...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hXFe6MQ3fBre",
    "outputId": "f587b900-2821-41a5-ab12-8951789c5f01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a nurse reading treatment notes and trying to figure out what topic is discussed and will return the result in JSON output:\n",
      "\n",
      "You are looking for below topics:\n",
      " -  Allergy / Immunology\n",
      " -  Bariatrics\n",
      " -  Cardiovascular / Pulmonary\n",
      " -  Neurology\n",
      " -  Dentistry\n",
      " -  Urology\n",
      " -  General Medicine\n",
      " -  Surgery\n",
      " -  Speech - Language\n",
      " -  SOAP / Chart / Progress Notes\n",
      " -  Sleep Medicine\n",
      " -  Rheumatology\n",
      " -  Radiology\n",
      " -  Psychiatry / Psychology\n",
      " -  Podiatry\n",
      " -  Physical Medicine - Rehab\n",
      " -  Pediatrics - Neonatal\n",
      " -  Pain Management\n",
      " -  Orthopedic\n",
      " -  Ophthalmology\n",
      " -  Office Notes\n",
      " -  Obstetrics / Gynecology\n",
      " -  Neurosurgery\n",
      " -  Nephrology\n",
      " -  Letters\n",
      " -  Lab Medicine - Pathology\n",
      " -  IME-QME-Work Comp etc.\n",
      " -  Hospice - Palliative Care\n",
      " -  Hematology - Oncology\n",
      " -  Gastroenterology\n",
      " -  ENT - Otolaryngology\n",
      " -  Endocrinology\n",
      " -  Emergency Room Reports\n",
      " -  Discharge Summary\n",
      " -  Diets and Nutritions\n",
      " -  Dermatology\n",
      " -  Cosmetic / Plastic Surgery\n",
      " -  Consult - History and Phy.\n",
      " -  Chiropractic\n",
      " -  Autopsy\n",
      "\n",
      "Requirements:\n",
      "• Read the notes carefully and see if the note is talking about the topics you know.\n",
      "• If the note is not talking about the topics you know, figure out it shows other topics.\n",
      "• Present your analysis in a JSON format. The format should be {{\"topic\": \"identified topic or new topic\"}}.\n",
      "\n",
      "Treatment notes to analyze:\n",
      "{text}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define prompt\n",
    "prompt_template = \"\"\"\n",
    "You are a nurse reading treatment notes and trying to figure out what topic is discussed and will return the result in JSON output:\n",
    "\n",
    "You are looking for below topics:\"\"\"\n",
    "prompt_template += specialties_text\n",
    "\n",
    "prompt_template += \"\"\"\n",
    "\n",
    "Requirements:\n",
    "• Read the notes carefully and see if the note is talking about the topics you know.\n",
    "• If the note is not talking about the topics you know, figure out it shows other topics.\n",
    "• Present your analysis in a JSON format. The format should be {{\"topic\": \"identified topic or new topic\"}}.\n",
    "\n",
    "Treatment notes to analyze:\n",
    "{text}\n",
    "\"\"\"\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "ouCTV0MxeIJq",
    "outputId": "2a11d03a-c28f-4550-f3ab-3605d5aca30a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUBJECTIVE:,  This 23-year-old white female presents with complaint of allergies.  She used to have allergies when she lived in Seattle but she thinks they are worse here.  In the past, she has tried Claritin, and Zyrtec.  Both worked for short time but then seemed to lose effectiveness.  She has used Allegra also.  She used that last summer and she began using it again two weeks ago.  It does not appear to be working very well.  She has used over-the-counter sprays but no prescription nasal sprays.  She does have asthma but doest not require daily medication for this and does not think it is flaring up.,MEDICATIONS: , Her only medication currently is Ortho Tri-Cyclen and the Allegra.,ALLERGIES: , She has no known medicine allergies.,OBJECTIVE:,Vitals:  Weight was 130 pounds and blood pressure 124/78.,HEENT:  Her throat was mildly erythematous without exudate.  Nasal mucosa was erythematous and swollen.  Only clear drainage was seen.  TMs were clear.,Neck:  Supple without adenopathy.,Lungs:  Clear.,ASSESSMENT:,  Allergic rhinitis.,PLAN:,1.  She will try Zyrtec instead of Allegra again.  Another option will be to use loratadine.  She does not think she has prescription coverage so that might be cheaper.,2.  Samples of Nasonex two sprays in each nostril given for three weeks.  A prescription was written as well.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_notes = data['transcription'].loc[0]\n",
    "patient_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oC2eYglGMxqj",
    "outputId": "d3a73d35-8f6b-44f2-a76a-07922cebf762"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:13<00:00, 13.16s/it]\n"
     ]
    }
   ],
   "source": [
    "prompt = f'''<|prompter|>:{prompt_template.format(text=patient_notes)}\\n<|assistant|>:JSON:\\n'''\n",
    "prompts = [prompt]\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0.01,\n",
    "    top_p=0.95,\n",
    "    top_k=50,\n",
    "    max_tokens=256\n",
    ")\n",
    "\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "response = outputs[0].outputs[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "niXaxFFpNmUR",
    "outputId": "ec0d544e-f139-4b42-8a3b-ef9fe3ad8680"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"topic\": \"Allergy / Immunology\"\n",
      "}\n",
      "\n",
      "Explanation:\n",
      "The topic of the treatment notes is Allergy / Immunology because the patient is presenting with complaints of allergies and the assessment is allergic rhinitis. The treatment plan also includes medications and samples of nasal sprays to alleviate allergy symptoms.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "def parse_llm_output(text):\n",
    "    \n",
    "    # Find all matches\n",
    "    pattern = r'\\{([^}]*)\\}'\n",
    "    matched_text = re.findall(pattern, text)\n",
    "    text = \"{\" + matched_text[0] + \"}\"\n",
    "\n",
    "    return json.loads(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1gC1StcLNgaQ",
    "outputId": "431de295-fb7d-4653-c61a-732ce34335e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'Allergy / Immunology'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_llm_output(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "P_drrB7HOFlN",
    "outputId": "3457c3ca-0e5e-4bf8-85f9-9dd87bd3e87e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Allergy / Immunology'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['medical_specialty'].loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMxpHlxyOB-D"
   },
   "source": [
    "# Case: Medical specialty classification & keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-4SJ4z3ZeIPf",
    "outputId": "1496dd42-664c-4a86-f452-f0de9cb84413"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a nurse reading treatment notes and trying to figure out what topic is discussed and will return the result in JSON output:\n",
      "\n",
      "You are looking for below topics:\n",
      " -  Allergy / Immunology\n",
      " -  Bariatrics\n",
      " -  Cardiovascular / Pulmonary\n",
      " -  Neurology\n",
      " -  Dentistry\n",
      " -  Urology\n",
      " -  General Medicine\n",
      " -  Surgery\n",
      " -  Speech - Language\n",
      " -  SOAP / Chart / Progress Notes\n",
      " -  Sleep Medicine\n",
      " -  Rheumatology\n",
      " -  Radiology\n",
      " -  Psychiatry / Psychology\n",
      " -  Podiatry\n",
      " -  Physical Medicine - Rehab\n",
      " -  Pediatrics - Neonatal\n",
      " -  Pain Management\n",
      " -  Orthopedic\n",
      " -  Ophthalmology\n",
      " -  Office Notes\n",
      " -  Obstetrics / Gynecology\n",
      " -  Neurosurgery\n",
      " -  Nephrology\n",
      " -  Letters\n",
      " -  Lab Medicine - Pathology\n",
      " -  IME-QME-Work Comp etc.\n",
      " -  Hospice - Palliative Care\n",
      " -  Hematology - Oncology\n",
      " -  Gastroenterology\n",
      " -  ENT - Otolaryngology\n",
      " -  Endocrinology\n",
      " -  Emergency Room Reports\n",
      " -  Discharge Summary\n",
      " -  Diets and Nutritions\n",
      " -  Dermatology\n",
      " -  Cosmetic / Plastic Surgery\n",
      " -  Consult - History and Phy.\n",
      " -  Chiropractic\n",
      " -  Autopsy\n",
      "\n",
      "Requirements:\n",
      "• Read the notes carefully and see if the note is talking about the topics you know.\n",
      "• If the note is not talking about the topics you know, figure out it shows other topics.\n",
      "• Extract keywords from the notes that are general and indicative of the identified topic.\n",
      "• Make sure that these keywords are written at treatment notes, don't include numeric numbers.\n",
      "• Please, fill the confidence level about the chosen topic within the next options: very confident, need more info, unconfident, not enough data.\n",
      "• Present your analysis in a JSON format. The format should be {{\"topic\": \"identified topic or new topic\", \"keywords\": [\"keyword1\", \"keyword2\", ...], \"confidence level\": \"very confident|need more info|unconfident|not enough data\", \"explanation\": \"briefly describe your analysis\"}}.\n",
      "\n",
      "\n",
      "Treatment notes to analyze:\n",
      "{text}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define prompt\n",
    "prompt_template = \"\"\"\n",
    "You are a nurse reading treatment notes and trying to figure out what topic is discussed and will return the result in JSON output:\n",
    "\n",
    "You are looking for below topics:\"\"\"\n",
    "prompt_template += specialties_text\n",
    "\n",
    "prompt_template += \"\"\"\n",
    "\n",
    "Requirements:\n",
    "• Read the notes carefully and see if the note is talking about the topics you know.\n",
    "• If the note is not talking about the topics you know, figure out it shows other topics.\n",
    "• Extract keywords from the notes that are general and indicative of the identified topic.\n",
    "• Make sure that these keywords are written at treatment notes, don't include numeric numbers.\n",
    "• Please, fill the confidence level about the chosen topic within the next options: very confident, need more info, unconfident, not enough data.\n",
    "• Present your analysis in a JSON format. The format should be {{\"topic\": \"identified topic or new topic\", \"keywords\": [\"keyword1\", \"keyword2\", ...], \"confidence level\": \"very confident|need more info|unconfident|not enough data\", \"explanation\": \"briefly describe your analysis\"}}.\n",
    "\n",
    "\n",
    "Treatment notes to analyze:\n",
    "{text}\n",
    "\"\"\"\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 160
    },
    "id": "pARftUTLN3dr",
    "outputId": "b424a668-3d3b-4bac-93c7-d134a6d7b75b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:18<00:00, 18.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 437 ms, sys: 32.4 ms, total: 469 ms\n",
      "Wall time: 18 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\\n  \"topic\": \"Allergy / Immunology\",\\n  \"keywords\": [\"allergies\", \"Claritin\", \"Zyrtec\", \"Allegra\", \"nasal sprays\", \"asthma\", \"Allergic rhinitis\"],\\n  \"confidence level\": \"very confident\",\\n  \"explanation\": \"The patient presents with complaints of allergies and has a history of using various medications for allergies. The physician also diagnoses the patient with allergic rhinitis.\"\\n}'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "prompt = f'''<|prompter|>:{prompt_template.format(text=patient_notes)}\\n<|assistant|>:JSON:\\n'''\n",
    "prompts = [prompt]\n",
    "\n",
    "sampling_params = SamplingParams(\n",
    "    temperature=0.01,\n",
    "    top_p=0.95,\n",
    "    top_k=50,\n",
    "    max_tokens=256\n",
    ")\n",
    "\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "response = outputs[0].outputs[0].text\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eIK_giteN3gY",
    "outputId": "90235201-26ee-4f61-9aef-ab2f11da4ce2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'Allergy / Immunology',\n",
       " 'keywords': ['allergies',\n",
       "  'Claritin',\n",
       "  'Zyrtec',\n",
       "  'Allegra',\n",
       "  'nasal sprays',\n",
       "  'asthma',\n",
       "  'Allergic rhinitis'],\n",
       " 'confidence level': 'very confident',\n",
       " 'explanation': 'The patient presents with complaints of allergies and has a history of using various medications for allergies. The physician also diagnoses the patient with allergic rhinitis.'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_llm_output(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YkDlTLHFN3ja",
    "outputId": "2868717c-a581-4575-c149-6fddd7c497ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': ' A 23-year-old white female presents with complaint of allergies.',\n",
       " 'medical_specialty': ' Allergy / Immunology',\n",
       " 'keywords': 'allergy / immunology, allergic rhinitis, allergies, asthma, nasal sprays, rhinitis, nasal, erythematous, allegra, sprays, allergic,'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[0][['description', 'medical_specialty', 'keywords']].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M5IQu93sN3lf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MnPrsPEQN3oP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "common-gpu.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-gpu:m112"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
